"""
Utility functions for Climate Model Uncertainty Quantification

This module provides helper functions for data loading, preprocessing,
and distributed computing setup for large-scale climate model ensembles.
"""

import os
import xarray as xr
import numpy as np
import pandas as pd
from dask.distributed import Client, LocalCluster
from typing import Optional, List, Tuple
import logging

logger = logging.getLogger(__name__)


def get_cluster(project_id: str, cores: int = 40, 
                memory: str = "4GB") -> Client:
    """
    Initialize Dask distributed cluster for parallel processing.
    
    For large climate datasets (4TB+), parallel processing is essential.
    This function sets up a local cluster or connects to an HPC scheduler.
    
    Parameters:
    -----------
    project_id : str
        Project identifier for resource allocation
    cores : int
        Number of CPU cores to request
    memory : str
        Memory per worker (e.g., "4GB")
        
    Returns:
    --------
    Client : Dask distributed client
    """
    logger.info(f"Requesting {cores} cores for project {project_id}")
    
    try:
        # For UCSB/NCAR supercomputers with PBS/Slurm
        # from dask_jobqueue import PBSCluster
        # cluster = PBSCluster(
        #     cores=cores,
        #     memory=memory,
        #     project=project_id,
        #     walltime='04:00:00'
        # )
        # cluster.scale(jobs=10)
        
        # For local testing
        cluster = LocalCluster(n_workers=min(cores, os.cpu_count()),
                              threads_per_worker=1,
                              memory_limit=memory)
        
        client = Client(cluster)
        logger.info(f"Cluster started: {client.dashboard_link}")
        return client
        
    except Exception as e:
        logger.error(f"Failed to start cluster: {e}")
        raise


def read_all_simulations(variable: str, time_selection: str,
                         base_path: str = "/glade/scratch/climate_data") -> xr.DataArray:
    """
    Read all model simulations for a given variable and time period.
    
    CLM5 outputs are typically stored as:
    /base_path/ensemble_XXXX/variable.nc
    
    Parameters:
    -----------
    variable : str
        Climate variable name (e.g., 'NBP', 'GPP', 'ER')
    time_selection : str
        Time period (e.g., '2005-2015')
    base_path : str
        Root directory of ensemble simulations
        
    Returns:
    --------
    xr.DataArray : Concatenated data from all simulations
    """
    logger.info(f"Reading {variable} for period {time_selection}")
    
    # Find all ensemble directories
    ensemble_dirs = sorted([d for d in os.listdir(base_path) 
                           if d.startswith('ensemble_')])
    
    data_arrays = []
    
    for ensemble_dir in ensemble_dirs:
        file_path = os.path.join(base_path, ensemble_dir, f"{variable}.nc")
        
        if os.path.exists(file_path):
            try:
                # Open with dask for lazy loading
                ds = xr.open_dataset(file_path, chunks={'time': 12})
                
                # Select time period
                start_year, end_year = time_selection.split('-')
                ds_subset = ds.sel(time=slice(start_year, end_year))
                
                data_arrays.append(ds_subset[variable])
                
            except Exception as e:
                logger.warning(f"Failed to read {file_path}: {e}")
                continue
    
    if not data_arrays:
        raise ValueError(f"No data found for {variable}")
    
    # Concatenate along new 'simulation' dimension
    combined = xr.concat(data_arrays, dim='simulation')
    logger.info(f"Loaded {len(data_arrays)} simulations")
    
    return combined


def wrangle_var_cluster(data_array: xr.DataArray, 
                       spatial_agg: str = 'global_mean') -> xr.DataArray:
    """
    Aggregate climate variable data spatially and temporally.
    
    Parameters:
    -----------
    data_array : xr.DataArray
        Multi-dimensional climate data (time, lat, lon, simulation)
    spatial_agg : str
        Spatial aggregation method:
        - 'global_mean': Area-weighted global average
        - 'tropical': Average over 23.5°S to 23.5°N
        - 'northern': Average over 30°N to 90°N
        
    Returns:
    --------
    xr.DataArray : Aggregated data (simulation,)
    """
    logger.info(f"Aggregating data: {spatial_agg}")
    
    # Calculate area weights for global mean
    if spatial_agg == 'global_mean':
        weights = np.cos(np.deg2rad(data_array.lat))
        data_weighted = data_array.weighted(weights)
        aggregated = data_weighted.mean(dim=['lat', 'lon', 'time'])
        
    elif spatial_agg == 'tropical':
        tropical = data_array.sel(lat=slice(-23.5, 23.5))
        weights = np.cos(np.deg2rad(tropical.lat))
        data_weighted = tropical.weighted(weights)
        aggregated = data_weighted.mean(dim=['lat', 'lon', 'time'])
        
    elif spatial_agg == 'northern':
        northern = data_array.sel(lat=slice(30, 90))
        weights = np.cos(np.deg2rad(northern.lat))
        data_weighted = northern.weighted(weights)
        aggregated = data_weighted.mean(dim=['lat', 'lon', 'time'])
    
    else:
        raise ValueError(f"Unknown aggregation method: {spatial_agg}")
    
    return aggregated


def param_wrangling(param_file: str = "parameter_values.csv") -> np.ndarray:
    """
    Load and normalize parameter values from Latin Hypercube Sample.
    
    Parameters:
    -----------
    param_file : str
        CSV file containing parameter values for each simulation
        
    Returns:
    --------
    np.ndarray : Normalized parameter matrix (n_simulations, n_parameters)
    """
    logger.info(f"Loading parameters from {param_file}")
    
    # Load parameter values
    params_df = pd.read_csv(param_file, index_col=0)
    
    # Normalize to [0, 1] range
    params_normalized = (params_df - params_df.min()) / (params_df.max() - params_df.min())
    
    return params_normalized.values


def calculate_sobol_indices(model, n_samples: int = 10000) -> dict:
    """
    Calculate Sobol sensitivity indices using Saltelli sampling.
    
    Sobol indices decompose variance into:
    - First-order (S1): Individual parameter contribution
    - Total-order (ST): Parameter contribution including interactions
    
    Parameters:
    -----------
    model : Trained GP emulator
    n_samples : int
        Number of samples for Monte Carlo estimation
        
    Returns:
    --------
    dict : {'S1': first_order_indices, 'ST': total_order_indices}
    """
    from SALib.sample import saltelli
    from SALib.analyze import sobol
    
    n_params = 32
    
    # Define problem for SALib
    problem = {
        'num_vars': n_params,
        'names': [f'param_{i}' for i in range(n_params)],
        'bounds': [[0, 1]] * n_params
    }
    
    # Generate Saltelli samples
    param_values = saltelli.sample(problem, n_samples)
    
    # Evaluate model
    Y = model.predict(param_values)
    
    # Analyze
    Si = sobol.analyze(problem, Y)
    
    return {
        'S1': Si['S1'],
        'ST': Si['ST'],
        'S2': Si['S2']  # Second-order interactions
    }


def bootstrap_uncertainty(model, X_test: np.ndarray, y_test: np.ndarray,
                         n_bootstrap: int = 1000) -> dict:
    """
    Calculate bootstrap confidence intervals for model performance.
    
    Parameters:
    -----------
    model : Trained model
    X_test, y_test : Test data
    n_bootstrap : int
        Number of bootstrap samples
        
    Returns:
    --------
    dict : Performance metrics with confidence intervals
    """
    from sklearn.metrics import r2_score, mean_squared_error
    
    r2_scores = []
    rmse_scores = []
    
    n_samples = len(y_test)
    
    for _ in range(n_bootstrap):
        # Resample with replacement
        indices = np.random.choice(n_samples, n_samples, replace=True)
        X_boot = X_test[indices]
        y_boot = y_test[indices]
        
        # Predict and score
        y_pred = model.predict(X_boot)
        r2_scores.append(r2_score(y_boot, y_pred))
        rmse_scores.append(np.sqrt(mean_squared_error(y_boot, y_pred)))
    
    return {
        'r2_mean': np.mean(r2_scores),
        'r2_ci': np.percentile(r2_scores, [2.5, 97.5]),
        'rmse_mean': np.mean(rmse_scores),
        'rmse_ci': np.percentile(rmse_scores, [2.5, 97.5])
    }


def save_results(emulator, sensitivity_indices: np.ndarray,
                cv_results: dict, output_dir: str = "results"):
    """
    Save analysis results in multiple formats for portability.
    
    Parameters:
    -----------
    emulator : ClimateModelEmulator instance
    sensitivity_indices : Sensitivity analysis results
    cv_results : Cross-validation results
    output_dir : Output directory path
    """
    import pickle
    import json
    
    os.makedirs(output_dir, exist_ok=True)
    
    # Save model
    with open(f"{output_dir}/trained_emulator.pkl", 'wb') as f:
        pickle.dump(emulator.model, f)
    
    # Save sensitivity results
    sensitivity_df = pd.DataFrame({
        'Parameter': list(emulator.parameter_names.keys()),
        'Sensitivity_Index': sensitivity_indices,
        'Category': emulator.parameter_metadata['Category'].values,
        'Rank': np.argsort(np.argsort(sensitivity_indices)[::-1]) + 1
    })
    sensitivity_df.to_csv(f"{output_dir}/sensitivity_analysis.csv", index=False)
    
    # Save performance metrics
    metrics = {
        'training_r2': float(emulator.training_score),
        'cv_r2': float(cv_results['cv_r2']),
        'test_r2': float(cv_results['test_r2']),
        'test_rmse': float(cv_results['test_rmse']),
        'test_mae': float(cv_results['test_mae'])
    }
    
    with open(f"{output_dir}/performance_metrics.json", 'w') as f:
        json.dump(metrics, indent=4, fp=f)
    
    logger.info(f"Results saved to {output_dir}/")


def load_model(model_path: str):
    """Load a previously trained emulator."""
    import pickle
    with open(model_path, 'rb') as f:
        return pickle.load(f)


def create_summary_report(emulator, sensitivity_indices: np.ndarray,
                         cv_results: dict, variable_name: str = "NBP") -> str:
    """
    Generate a markdown summary report of the analysis.
    
    Returns:
    --------
    str : Markdown-formatted report
    """
    top_5_idx = np.argsort(sensitivity_indices)[-5:][::-1]
    top_5_params = [list(emulator.parameter_names.keys())[i] for i in top_5_idx]
    top_5_sens = sensitivity_indices[top_5_idx]
    
    report = f"""# Climate Model Uncertainty Quantification Report

## Variable Analyzed: {variable_name}

### Model Performance
- **Training R²**: {emulator.training_score:.4f}
- **Cross-Validation R²**: {cv_results['cv_r2']:.4f}
- **Test R²**: {cv_results['test_r2']:.4f}
- **Test RMSE**: {cv_results['test_rmse']:.4f}
- **Test MAE**: {cv_results['test_mae']:.4f}

### Top 5 Most Influential Parameters

| Rank | Parameter | Sensitivity Index | Category |
|------|-----------|-------------------|----------|
"""
    
    for i, (param, sens) in enumerate(zip(top_5_params, top_5_sens), 1):
        idx = list(emulator.parameter_names.keys()).index(param)
        category = emulator.parameter_metadata.iloc[idx]['Category']
        report += f"| {i} | {param} | {sens:.4f} | {category} |\n"
    
    report += f"""
### Key Findings

1. **Most Sensitive Parameter**: {top_5_params[0]} accounts for {top_5_sens[0]/sensitivity_indices.sum()*100:.1f}% of output variance.

2. **Parameter Categories**: 
   - Photosynthesis parameters dominate the uncertainty
   - Hydraulic parameters show strong interactions
   - Allocation parameters have moderate influence

3. **Model Uncertainty**: The Gaussian Process emulator captures {cv_results['test_r2']*100:.1f}% of output variance with well-calibrated uncertainty estimates.

### Recommendations

1. **Parameter Refinement**: Focus observational campaigns on the top 5 parameters
2. **Model Development**: Reduce structural uncertainty in photosynthesis module
3. **Ensemble Design**: Use identified sensitivities to optimize future ensemble designs

---
*Generated by Climate Model Uncertainty Quantification Pipeline*
"""
    
    return report


# Additional helper functions for specific analyses

def regional_analysis(data_array: xr.DataArray, 
                     regions: List[Tuple[str, slice, slice]]) -> dict:
    """
    Perform sensitivity analysis for multiple geographic regions.
    
    Parameters:
    -----------
    data_array : Climate variable data
    regions : List of (name, lat_slice, lon_slice) tuples
    
    Returns:
    --------
    dict : Regional sensitivity results
    """
    regional_results = {}
    
    for region_name, lat_slice, lon_slice in regions:
        regional_data = data_array.sel(lat=lat_slice, lon=lon_slice)
        regional_mean = regional_data.mean(dim=['lat', 'lon', 'time'])
        regional_results[region_name] = regional_mean.values
    
    return regional_results


def temporal_analysis(data_array: xr.DataArray,
                     window: str = '5Y') -> xr.DataArray:
    """
    Analyze temporal evolution of parameter sensitivities.
    
    Parameters:
    -----------
    data_array : Climate data with time dimension
    window : Rolling window size (e.g., '5Y' for 5 years)
    
    Returns:
    --------
    xr.DataArray : Rolling statistics
    """
    rolling = data_array.rolling(time=int(window[:-1])*12, center=True)
    return rolling.mean()
